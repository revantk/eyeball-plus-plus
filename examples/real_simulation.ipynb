{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eyeball Simulation Demo\n",
    "This notebook provides an example of how `eyeball_pp` can be used effectively during development. We'll show eyeball's recording, rerunning and evaluation systems in action under 3 scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Setup\n",
    "Lets install required modules and set up eyeball and openai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install eyeball_pp openai pyyaml rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eyeball_pp\n",
    "import openai\n",
    "\n",
    "openai.api_key = \"your-openai-key\"\n",
    "\n",
    "# Setting a sample_rate of 1 means that every call to the ask function will be recorded.\n",
    "# You might want to change this on production to a lower value like 0.1 if you only want to record 10% of the calls.\n",
    "eyeball_pp.set_config(sample_rate=1)\n",
    "\n",
    "def _execute_completion(system_msg: str, prompt: str, model: str) -> str:\n",
    "    \"\"\"Convenience method for executing a completion.\"\"\"\n",
    "    return openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. First Run: 3 Failures\n",
    "This run does the initial recording of the inputs and has 3 failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eyeball_pp.record_task(input_names=[\"context\", \"question\"])\n",
    "def ask(context: str, question: str) -> str:\n",
    "\n",
    "    model = eyeball_pp.get_eval_param(\"model\") or \"gpt-3.5-turbo\"\n",
    "    \n",
    "    system = \"\"\"\n",
    "    You are trying to answer a question strictly using the information provided in the context. Reply \"I don't know\" if you don't know the answer.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Context: {context}\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "\n",
    "    return _execute_completion(system, prompt, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_inputs = [\n",
    "    {\n",
    "        \"context\": \"The quick brown fox jumps over the lazy dog\", \n",
    "        \"question\": \"What color is the fox?\"\n",
    "    }, {\n",
    "        \"context\": \"The lazy green dog jumps over the quick brown fox\", \n",
    "        \"question\": \"What color is the dog?\"\n",
    "    }, {\n",
    "        \"context\": \"Peter Piper picked a peck of pickled peppers\", \n",
    "        \"question\": \"How would you describe the peppers?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "def _answer_and_print(context, question):\n",
    "    answer = ask(context, question)\n",
    "    print(f\"Context  : {input['context']}\")\n",
    "    print(f\"Question : {input['question']}\")\n",
    "    print(f\"Answer   : {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context  : The quick brown fox jumps over the lazy dog\n",
      "Question : What color is the fox?\n",
      "Answer   : I don't know.\n",
      "\n",
      "Context  : The lazy green dog jumps over the quick brown fox\n",
      "Question : What color is the dog?\n",
      "Answer   : I don't know.\n",
      "\n",
      "Context  : Peter Piper picked a peck of pickled peppers\n",
      "Question : How would you describe the peppers?\n",
      "Answer   : I don't know.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for input in sample_inputs:\n",
    "    _answer_and_print(**input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 3 inputs for task:`ask`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inputs: 100%|██████████|3/3"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "---------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">Ovearall system health for task: ask                                </span>\n",
       "┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> date       </span>┃<span style=\"font-weight: bold\"> sucess percentage </span>┃<span style=\"font-weight: bold\"> # checkpoints </span>┃<span style=\"font-weight: bold\"> # unique inputs </span>┃\n",
       "┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ 2023-08-09 │  0.0%             │ 3             │ 3               │\n",
       "└────────────┴───────────────────┴───────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3mOvearall system health for task: ask                                \u001b[0m\n",
       "┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mdate      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1msucess percentage\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m# checkpoints\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m# unique inputs\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ 2023-08-09 │  0.0%             │ 3             │ 3               │\n",
       "└────────────┴───────────────────┴───────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">System health broken down by run history                                    </span>\n",
       "┏━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> run history     </span>┃<span style=\"font-weight: bold\"> task_output                      </span>┃<span style=\"font-weight: bold\"> # unique inputs run </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ 09 Aug - 10 Aug │  0.0% (0/3) runs were successful │ 3                   │\n",
       "└─────────────────┴──────────────────────────────────┴─────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3mSystem health broken down by run history                                    \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mrun history    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mtask_output                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m# unique inputs run\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ 09 Aug - 10 Aug │  0.0% (0/3) runs were successful │ 3                   │\n",
       "└─────────────────┴──────────────────────────────────┴─────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">Task success breakdown by input                                                                                    </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> context                 </span>┃<span style=\"font-weight: bold\"> question                </span>┃<span style=\"font-weight: bold\"> best_checkpoint </span>┃<span style=\"font-weight: bold\"> most_recent_checkpoint </span>┃<span style=\"font-weight: bold\"> worst_checkpoint </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
       "│ \"The quick brown fox    │ \"What color is the      │ @ 17 hours ago  │ @ 17 hours ago         │ @ 17 hours ago   │\n",
       "│ jumps over the lazy     │ fox?\"                   │ score: 0.00     │ score: 0.00            │ score: 0.00      │\n",
       "│ dog\"                    │                         │ \"I don't know.\" │ \"I don't know.\"        │ \"I don't know.\"  │\n",
       "│ \"The lazy green dog     │ \"What color is the      │ @ 17 hours ago  │ @ 17 hours ago         │ @ 17 hours ago   │\n",
       "│ jumps over the quick    │ dog?\"                   │ score: 0.00     │ score: 0.00            │ score: 0.00      │\n",
       "│ brown fox\"              │                         │ \"I don't know.\" │ \"I don't know.\"        │ \"I don't know.\"  │\n",
       "│ \"Peter Piper picked a   │ \"How would you describe │ @ 17 hours ago  │ @ 17 hours ago         │ @ 17 hours ago   │\n",
       "│ peck of pickled         │ the peppers?\"           │ score: 0.00     │ score: 0.00            │ score: 0.00      │\n",
       "│ peppers\"                │                         │ \"I don't know.\" │ \"I don't know.\"        │ \"I don't know.\"  │\n",
       "└─────────────────────────┴─────────────────────────┴─────────────────┴────────────────────────┴──────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3mTask success breakdown by input                                                                                    \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mcontext                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mquestion               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mbest_checkpoint\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmost_recent_checkpoint\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mworst_checkpoint\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
       "│ \"The quick brown fox    │ \"What color is the      │ @ 17 hours ago  │ @ 17 hours ago         │ @ 17 hours ago   │\n",
       "│ jumps over the lazy     │ fox?\"                   │ score: 0.00     │ score: 0.00            │ score: 0.00      │\n",
       "│ dog\"                    │                         │ \"I don't know.\" │ \"I don't know.\"        │ \"I don't know.\"  │\n",
       "│ \"The lazy green dog     │ \"What color is the      │ @ 17 hours ago  │ @ 17 hours ago         │ @ 17 hours ago   │\n",
       "│ jumps over the quick    │ dog?\"                   │ score: 0.00     │ score: 0.00            │ score: 0.00      │\n",
       "│ brown fox\"              │                         │ \"I don't know.\" │ \"I don't know.\"        │ \"I don't know.\"  │\n",
       "│ \"Peter Piper picked a   │ \"How would you describe │ @ 17 hours ago  │ @ 17 hours ago         │ @ 17 hours ago   │\n",
       "│ peck of pickled         │ the peppers?\"           │ score: 0.00     │ score: 0.00            │ score: 0.00      │\n",
       "│ peppers\"                │                         │ \"I don't know.\" │ \"I don't know.\"        │ \"I don't know.\"  │\n",
       "└─────────────────────────┴─────────────────────────┴─────────────────┴────────────────────────┴──────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from eyeball_pp import Criteria\n",
    "\n",
    "eyeball_pp.evaluate_system(\n",
    "    grading_criteria=[Criteria.CORRECTNESS, Criteria.RELEVANCE]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Second Run: 2 Success, 1 Failure\n",
    "This run makes a tweak to the `ask` function by changing the \"system\" prompt, and then reruns all recorded examples. The result is that 2 of the requests succeed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eyeball_pp.record_task(input_names=[\"context\", \"question\"])\n",
    "def ask(context: str, question: str) -> str:\n",
    "\n",
    "    model = eyeball_pp.get_eval_param(\"model\") or \"gpt-3.5-turbo\"\n",
    "    \n",
    "    system = \"\"\"\n",
    "    You are trying to answer a question strictly using the information provided in the context. Think step by step. Reply \"I don't know\" if you don't know the answer.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Context: {context}\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "\n",
    "    return _execute_completion(system, prompt, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will rerun 3 inputs for task:`ask`\n",
      "\n",
      "Rerunning input #0:\n",
      "context=\"The quick brown fox jumps over the lazy dog\"\n",
      "question=\"What color is the fox?\"\n",
      "\n",
      "Context  : The quick brown fox jumps over the lazy dog\n",
      "Question : What color is the fox?\n",
      "Answer   : I don't know.\n",
      "\n",
      "\n",
      "Rerunning input #1:\n",
      "context=\"The lazy green dog jumps over the quick brown fox\"\n",
      "question=\"What color is the dog?\"\n",
      "\n",
      "Context  : The lazy green dog jumps over the quick brown fox\n",
      "Question : What color is the dog?\n",
      "Answer   : The color of the dog is green.\n",
      "\n",
      "\n",
      "Rerunning input #2:\n",
      "context=\"Peter Piper picked a peck of pickled peppers\"\n",
      "question=\"How would you describe the peppers?\"\n",
      "\n",
      "Context  : Peter Piper picked a peck of pickled peppers\n",
      "Question : How would you describe the peppers?\n",
      "Answer   : The peppers are pickled.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recorded_inputs = eyeball_pp.rerun_recorded_examples()\n",
    "for input in recorded_inputs:\n",
    "    _answer_and_print(input[\"context\"], input[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 3 inputs for task:`ask`\n",
      "\n",
      "Input #0 - Grading 2 checkpoints\n",
      "Scored 2023-08-09T16:45:55.605154: 1.0\n",
      "Using cached score for 2023-08-09T16:34:19.644654: 0.0\n",
      "\n",
      "Input #0 - Running 1 comparison(s)\n",
      "\u001b[32m[improvement] task output improved from checkpoint 2023-08-09T16:34:19.644654  to 2023-08-09T16:45:55.605154 \u001b[0m\n",
      "\n",
      "Input #1 - Grading 2 checkpoints\n",
      "Scored 2023-08-09T16:45:55.012159: 0.0\n",
      "Using cached score for 2023-08-09T16:34:19.010248: 0.0\n",
      "\n",
      "Input #1 - Running 1 comparison(s)\n",
      "\u001b[33m[neutral] task output is the same between checkpoints 2023-08-09T16:34:19.010248  & 2023-08-09T16:45:55.012159  \u001b[0m\n",
      "\n",
      "Input #2 - Grading 2 checkpoints\n",
      "Scored 2023-08-09T16:45:56.185086: 1.0\n",
      "Using cached score for 2023-08-09T16:34:20.204640: 0.0\n",
      "\n",
      "Input #2 - Running 1 comparison(s)\n",
      "\u001b[32m[improvement] task output improved from checkpoint 2023-08-09T16:34:20.204640  to 2023-08-09T16:45:56.185086 \u001b[0m\n",
      "\n",
      "Summary:\n",
      "---------\n",
      "Your most sucessful re-runs:\n",
      "2023-08-09T16:45:55.011848: 3/3 successes\n",
      "\n",
      "Your most sucessful params:\n",
      "default: 4/3 successes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                Ovearll system health for task: ask                 </span>\n",
       "┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> date       </span>┃<span style=\"font-weight: bold\"> sucess percentage </span>┃<span style=\"font-weight: bold\"> # checkpoints </span>┃<span style=\"font-weight: bold\"> # unique inputs </span>┃\n",
       "┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ 2023-08-09 │  33.3%            │ 6             │ 3               │\n",
       "└────────────┴───────────────────┴───────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                Ovearll system health for task: ask                 \u001b[0m\n",
       "┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mdate      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1msucess percentage\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m# checkpoints\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m# unique inputs\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ 2023-08-09 │  33.3%            │ 6             │ 3               │\n",
       "└────────────┴───────────────────┴───────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                     System health broken down by run history                      </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> run history           </span>┃<span style=\"font-weight: bold\"> task_output                       </span>┃<span style=\"font-weight: bold\"> # unique inputs run </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Rerun on 09 Aug 16:45 │  66.7% (2/3) runs were successful │ 3                   │\n",
       "│ 09 Aug 16:34 - 16:45  │  0.0% (0/3) runs were successful  │ 3                   │\n",
       "└───────────────────────┴───────────────────────────────────┴─────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                     System health broken down by run history                      \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mrun history          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mtask_output                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m# unique inputs run\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Rerun on 09 Aug 16:45 │  66.7% (2/3) runs were successful │ 3                   │\n",
       "│ 09 Aug 16:34 - 16:45  │  0.0% (0/3) runs were successful  │ 3                   │\n",
       "└───────────────────────┴───────────────────────────────────┴─────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                          Task success breakdown by input                                          </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> context               </span>┃<span style=\"font-weight: bold\"> question              </span>┃<span style=\"font-weight: bold\"> best_checkpoint      </span>┃<span style=\"font-weight: bold\"> most_recent_checkpoi… </span>┃<span style=\"font-weight: bold\"> worst_checkpoint </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
       "│ \"The quick brown fox  │ \"What color is the    │ @ 17 hours ago       │ @ 17 hours ago        │ @ 17 hours ago   │\n",
       "│ jumps over the lazy   │ fox?\"                 │ score: 0.00          │ score: 0.00           │ score: 0.00      │\n",
       "│ dog\"                  │                       │ \"I don't know.\"      │ \"I don't know.\"       │ \"I don't know.\"  │\n",
       "│ \"The lazy green dog   │ \"What color is the    │ @ 17 hours ago       │ @ 17 hours ago        │ @ 17 hours ago   │\n",
       "│ jumps over the quick  │ dog?\"                 │ score: 1.00          │ score: 1.00           │ score: 0.00      │\n",
       "│ brown fox\"            │                       │ \"The color of the    │ \"The color of the dog │ \"I don't know.\"  │\n",
       "│                       │                       │ dog is green.\"       │ is green.\"            │                  │\n",
       "│ \"Peter Piper picked a │ \"How would you        │ @ 17 hours ago       │ @ 17 hours ago        │ @ 17 hours ago   │\n",
       "│ peck of pickled       │ describe the          │ score: 1.00          │ score: 1.00           │ score: 0.00      │\n",
       "│ peppers\"              │ peppers?\"             │ \"The peppers are     │ \"The peppers are      │ \"I don't know.\"  │\n",
       "│                       │                       │ pickled.\"            │ pickled.\"             │                  │\n",
       "└───────────────────────┴───────────────────────┴──────────────────────┴───────────────────────┴──────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                          Task success breakdown by input                                          \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mcontext              \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mquestion             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mbest_checkpoint     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmost_recent_checkpoi…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mworst_checkpoint\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
       "│ \"The quick brown fox  │ \"What color is the    │ @ 17 hours ago       │ @ 17 hours ago        │ @ 17 hours ago   │\n",
       "│ jumps over the lazy   │ fox?\"                 │ score: 0.00          │ score: 0.00           │ score: 0.00      │\n",
       "│ dog\"                  │                       │ \"I don't know.\"      │ \"I don't know.\"       │ \"I don't know.\"  │\n",
       "│ \"The lazy green dog   │ \"What color is the    │ @ 17 hours ago       │ @ 17 hours ago        │ @ 17 hours ago   │\n",
       "│ jumps over the quick  │ dog?\"                 │ score: 1.00          │ score: 1.00           │ score: 0.00      │\n",
       "│ brown fox\"            │                       │ \"The color of the    │ \"The color of the dog │ \"I don't know.\"  │\n",
       "│                       │                       │ dog is green.\"       │ is green.\"            │                  │\n",
       "│ \"Peter Piper picked a │ \"How would you        │ @ 17 hours ago       │ @ 17 hours ago        │ @ 17 hours ago   │\n",
       "│ peck of pickled       │ describe the          │ score: 1.00          │ score: 1.00           │ score: 0.00      │\n",
       "│ peppers\"              │ peppers?\"             │ \"The peppers are     │ \"The peppers are      │ \"I don't know.\"  │\n",
       "│                       │                       │ pickled.\"            │ pickled.\"             │                  │\n",
       "└───────────────────────┴───────────────────────┴──────────────────────┴───────────────────────┴──────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eyeball_pp.evaluate_system(\n",
    "    task_objective=\"This agent tries to answer questions given a context. Verify that the agent answers the question correctly and that the answer is only based on the context.\",\n",
    "    grading_criteria=[Criteria.CORRECTNESS, Criteria.RELEVANCE]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Run: 3 Success\n",
    "This run reruns recorded examples using the `gpt-4` model instead. The result is that all requests succeed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will rerun 3 inputs for task:`ask`\n",
      "\n",
      "Rerunning input #0:\n",
      "context=\"The quick brown fox jumps over the lazy dog\"\n",
      "question=\"What color is the fox?\"\n",
      "\n",
      "Using eval params: {'model': 'gpt-4'}\n",
      "Context  : The quick brown fox jumps over the lazy dog\n",
      "Question : What color is the fox?\n",
      "Answer   : The fox is brown.\n",
      "\n",
      "\n",
      "Rerunning input #1:\n",
      "context=\"The lazy green dog jumps over the quick brown fox\"\n",
      "question=\"What color is the dog?\"\n",
      "\n",
      "Using eval params: {'model': 'gpt-4'}\n",
      "Context  : The lazy green dog jumps over the quick brown fox\n",
      "Question : What color is the dog?\n",
      "Answer   : The dog is green.\n",
      "\n",
      "\n",
      "Rerunning input #2:\n",
      "context=\"Peter Piper picked a peck of pickled peppers\"\n",
      "question=\"How would you describe the peppers?\"\n",
      "\n",
      "Using eval params: {'model': 'gpt-4'}\n",
      "Context  : Peter Piper picked a peck of pickled peppers\n",
      "Question : How would you describe the peppers?\n",
      "Answer   : The peppers are described as pickled.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recorded_inputs = eyeball_pp.rerun_recorded_examples(\n",
    "    {\"model\": \"gpt-4\"}\n",
    ")\n",
    "for input in recorded_inputs:\n",
    "    _answer_and_print(**input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 3 inputs for task:`ask`\n",
      "\n",
      "Input #0 - Grading 3 checkpoints\n",
      "Scored 2023-08-09T16:54:17.211499: 1.0\n",
      "Using cached score for 2023-08-09T16:45:55.012159: 0.0\n",
      "Using cached score for 2023-08-09T16:34:19.010248: 0.0\n",
      "\n",
      "Input #0 - Running 2 comparison(s)\n",
      "\u001b[32m[improvement] task output improved from checkpoint 2023-08-09T16:45:55.012159  to 2023-08-09T16:54:17.211499 (model=gpt-4)\u001b[0m\n",
      "Using cached comparison result for 1ac98f2a029fafe8d8d8caa05df2d12402770d5e92e7eb61297ca2f0a7719aa8\n",
      "\u001b[33m[neutral] task output is the same between checkpoints 2023-08-09T16:34:19.010248  & 2023-08-09T16:45:55.012159  \u001b[0m\n",
      "\n",
      "Input #1 - Grading 3 checkpoints\n",
      "Scored 2023-08-09T16:54:18.785326: 1.0\n",
      "Using cached score for 2023-08-09T16:45:55.605154: 1.0\n",
      "Using cached score for 2023-08-09T16:34:19.644654: 0.0\n",
      "\n",
      "Input #1 - Running 2 comparison(s)\n",
      "\u001b[33m[neutral] task output is the same between checkpoints 2023-08-09T16:45:55.605154  & 2023-08-09T16:54:18.785326 (model=gpt-4) \u001b[0m\n",
      "Using cached comparison result for f2acee1f8e40bfd8a433fa76e0b98937ade3d4df7c92f612ddb2ec0e8244df93\n",
      "\u001b[32m[improvement] task output improved from checkpoint 2023-08-09T16:34:19.644654  to 2023-08-09T16:45:55.605154 \u001b[0m\n",
      "\n",
      "Input #2 - Grading 3 checkpoints\n",
      "Scored 2023-08-09T16:54:21.443880: 1.0\n",
      "Using cached score for 2023-08-09T16:45:56.185086: 1.0\n",
      "Using cached score for 2023-08-09T16:34:20.204640: 0.0\n",
      "\n",
      "Input #2 - Running 2 comparison(s)\n",
      "\u001b[33m[neutral] task output is the same between checkpoints 2023-08-09T16:45:56.185086  & 2023-08-09T16:54:21.443880 (model=gpt-4) \u001b[0m\n",
      "Using cached comparison result for cbf86c8bb0715af1cdc06af24cbff58bda94a5bb42c4a82e40ea02790d5c821b\n",
      "\u001b[32m[improvement] task output improved from checkpoint 2023-08-09T16:34:20.204640  to 2023-08-09T16:45:56.185086 \u001b[0m\n",
      "\n",
      "Summary:\n",
      "---------\n",
      "Your most sucessful re-runs:\n",
      "2023-08-09T16:45:55.011848: 5/3 successes\n",
      "2023-08-09T16:54:17.211167: 3/3 successes\n",
      "\n",
      "Your most sucessful params:\n",
      "default: 6/6 successes\n",
      "model=gpt-4: 3/6 successes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                Ovearll system health for task: ask                 </span>\n",
       "┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> date       </span>┃<span style=\"font-weight: bold\"> sucess percentage </span>┃<span style=\"font-weight: bold\"> # checkpoints </span>┃<span style=\"font-weight: bold\"> # unique inputs </span>┃\n",
       "┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ 2023-08-09 │  55.6%            │ 9             │ 3               │\n",
       "└────────────┴───────────────────┴───────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                Ovearll system health for task: ask                 \u001b[0m\n",
       "┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mdate      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1msucess percentage\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m# checkpoints\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m# unique inputs\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ 2023-08-09 │  55.6%            │ 9             │ 3               │\n",
       "└────────────┴───────────────────┴───────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                      System health broken down by run history                      </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> run history           </span>┃<span style=\"font-weight: bold\"> task_output                        </span>┃<span style=\"font-weight: bold\"> # unique inputs run </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Rerun on 09 Aug 16:54 │  100.0% (3/3) runs were successful │ 3                   │\n",
       "│ Rerun on 09 Aug 16:45 │  66.7% (2/3) runs were successful  │ 3                   │\n",
       "│ 09 Aug 16:34 - 16:45  │  0.0% (0/3) runs were successful   │ 3                   │\n",
       "└───────────────────────┴────────────────────────────────────┴─────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                      System health broken down by run history                      \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mrun history          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mtask_output                       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m# unique inputs run\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Rerun on 09 Aug 16:54 │  100.0% (3/3) runs were successful │ 3                   │\n",
       "│ Rerun on 09 Aug 16:45 │  66.7% (2/3) runs were successful  │ 3                   │\n",
       "│ 09 Aug 16:34 - 16:45  │  0.0% (0/3) runs were successful   │ 3                   │\n",
       "└───────────────────────┴────────────────────────────────────┴─────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                          Task success breakdown by input                                          </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> context               </span>┃<span style=\"font-weight: bold\"> question              </span>┃<span style=\"font-weight: bold\"> best_checkpoint      </span>┃<span style=\"font-weight: bold\"> most_recent_checkpoi… </span>┃<span style=\"font-weight: bold\"> worst_checkpoint </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
       "│ \"The quick brown fox  │ \"What color is the    │ @ 17 hours ago       │ @ 17 hours ago        │ @ 17 hours ago   │\n",
       "│ jumps over the lazy   │ fox?\"                 │ score: 1.00          │ score: 1.00           │ score: 0.00      │\n",
       "│ dog\"                  │                       │ (model=gpt-4)        │ (model=gpt-4)         │ \"I don't know.\"  │\n",
       "│                       │                       │ \"The fox is brown.\"  │ \"The fox is brown.\"   │                  │\n",
       "│ \"The lazy green dog   │ \"What color is the    │ @ 17 hours ago       │ @ 17 hours ago        │ @ 17 hours ago   │\n",
       "│ jumps over the quick  │ dog?\"                 │ score: 1.00          │ score: 1.00           │ score: 0.00      │\n",
       "│ brown fox\"            │                       │ \"The color of the    │ (model=gpt-4)         │ \"I don't know.\"  │\n",
       "│                       │                       │ dog is green.\"       │ \"The dog is green.\"   │                  │\n",
       "│ \"Peter Piper picked a │ \"How would you        │ @ 17 hours ago       │ @ 17 hours ago        │ @ 17 hours ago   │\n",
       "│ peck of pickled       │ describe the          │ score: 1.00          │ score: 1.00           │ score: 0.00      │\n",
       "│ peppers\"              │ peppers?\"             │ \"The peppers are     │ (model=gpt-4)         │ \"I don't know.\"  │\n",
       "│                       │                       │ pickled.\"            │ \"The peppers are      │                  │\n",
       "│                       │                       │                      │ described as          │                  │\n",
       "│                       │                       │                      │ pickled.\"             │                  │\n",
       "└───────────────────────┴───────────────────────┴──────────────────────┴───────────────────────┴──────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                          Task success breakdown by input                                          \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mcontext              \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mquestion             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mbest_checkpoint     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmost_recent_checkpoi…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mworst_checkpoint\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
       "│ \"The quick brown fox  │ \"What color is the    │ @ 17 hours ago       │ @ 17 hours ago        │ @ 17 hours ago   │\n",
       "│ jumps over the lazy   │ fox?\"                 │ score: 1.00          │ score: 1.00           │ score: 0.00      │\n",
       "│ dog\"                  │                       │ (model=gpt-4)        │ (model=gpt-4)         │ \"I don't know.\"  │\n",
       "│                       │                       │ \"The fox is brown.\"  │ \"The fox is brown.\"   │                  │\n",
       "│ \"The lazy green dog   │ \"What color is the    │ @ 17 hours ago       │ @ 17 hours ago        │ @ 17 hours ago   │\n",
       "│ jumps over the quick  │ dog?\"                 │ score: 1.00          │ score: 1.00           │ score: 0.00      │\n",
       "│ brown fox\"            │                       │ \"The color of the    │ (model=gpt-4)         │ \"I don't know.\"  │\n",
       "│                       │                       │ dog is green.\"       │ \"The dog is green.\"   │                  │\n",
       "│ \"Peter Piper picked a │ \"How would you        │ @ 17 hours ago       │ @ 17 hours ago        │ @ 17 hours ago   │\n",
       "│ peck of pickled       │ describe the          │ score: 1.00          │ score: 1.00           │ score: 0.00      │\n",
       "│ peppers\"              │ peppers?\"             │ \"The peppers are     │ (model=gpt-4)         │ \"I don't know.\"  │\n",
       "│                       │                       │ pickled.\"            │ \"The peppers are      │                  │\n",
       "│                       │                       │                      │ described as          │                  │\n",
       "│                       │                       │                      │ pickled.\"             │                  │\n",
       "└───────────────────────┴───────────────────────┴──────────────────────┴───────────────────────┴──────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eyeball_pp.evaluate_system(\n",
    "    task_objective=\"This agent tries to answer questions given a context. Verify that the agent answers the question correctly and that the answer is only based on the context.\",\n",
    "    grading_criteria=[Criteria.CORRECTNESS, Criteria.RELEVANCE]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
